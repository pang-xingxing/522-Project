{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# Importing necessary libraries","metadata":{}},{"cell_type":"code","source":"import torch\nimport torchvision\n\nimport pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport torch.nn as nn\nimport torch.nn.functional as F\nimport torchvision.models as models\nimport seaborn as sns\nsns.set_style(\"whitegrid\")\n\nfrom PIL import Image\nfrom tqdm.notebook import tqdm\nfrom torch.utils.data import DataLoader\nfrom torchvision import transforms\nfrom torchvision.datasets import ImageFolder\nfrom sklearn.metrics import precision_recall_fscore_support, confusion_matrix\n\n%matplotlib inline\n\nimport warnings\nwarnings.filterwarnings(\"ignore\")","metadata":{"execution":{"iopub.status.busy":"2022-04-27T02:15:26.562912Z","iopub.execute_input":"2022-04-27T02:15:26.563156Z","iopub.status.idle":"2022-04-27T02:15:29.173661Z","shell.execute_reply.started":"2022-04-27T02:15:26.563078Z","shell.execute_reply":"2022-04-27T02:15:29.172849Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def set_device():\n  \"\"\"\n  Set the device. CUDA if available, CPU otherwise\n\n  Args:\n    None\n\n  Returns:\n    Nothing\n  \"\"\"\n  device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n  if not torch.cuda.is_available():\n    print(\"WARNING: For this notebook to perform best, \"\n        \"if possible, in the menu under `Runtime` -> \"\n        \"`Change runtime type.`  select `GPU` \")\n  else:\n    print(\"GPU is enabled in this notebook.\")\n\n  return device\n\nDEVICE = set_device()\nprint(DEVICE)","metadata":{"execution":{"iopub.status.busy":"2022-04-27T02:15:33.732952Z","iopub.execute_input":"2022-04-27T02:15:33.733206Z","iopub.status.idle":"2022-04-27T02:15:33.797376Z","shell.execute_reply.started":"2022-04-27T02:15:33.733177Z","shell.execute_reply":"2022-04-27T02:15:33.796668Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Loading the data","metadata":{}},{"cell_type":"code","source":"train_dir = \"../input/chest-xray-pneumonia/chest_xray/train\"\ntest_dir = \"../input/chest-xray-pneumonia/chest_xray/test\"\nval_dir = \"../input/chest-xray-pneumonia/chest_xray/val\"","metadata":{"execution":{"iopub.status.busy":"2022-04-27T02:15:36.254377Z","iopub.execute_input":"2022-04-27T02:15:36.254962Z","iopub.status.idle":"2022-04-27T02:15:36.259138Z","shell.execute_reply.started":"2022-04-27T02:15:36.254918Z","shell.execute_reply":"2022-04-27T02:15:36.258024Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_transform = transforms.Compose((\n    transforms.Resize((256, 256)),\n    transforms.CenterCrop(224),\n    transforms.RandomAffine(\n        20, \n        shear=10,\n        interpolation=transforms.InterpolationMode.NEAREST\n    ),\n    transforms.RandomHorizontalFlip(p=0.2),\n    transforms.RandomVerticalFlip(p=0.2),\n    transforms.ColorJitter(brightness=[0.5,2.0]),\n    transforms.ToTensor()\n))\n\ntrain_image = ImageFolder(train_dir, transform=train_transform)\n\nval_transform = transforms.Compose((\n    transforms.Resize((256, 256)),\n    transforms.CenterCrop(224),\n    transforms.ToTensor()\n))\n\nval_image = ImageFolder(val_dir, transform=val_transform)\n\ntest_image = ImageFolder(test_dir, transform=val_transform)","metadata":{"execution":{"iopub.status.busy":"2022-04-27T02:15:37.579084Z","iopub.execute_input":"2022-04-27T02:15:37.579635Z","iopub.status.idle":"2022-04-27T02:15:40.754488Z","shell.execute_reply.started":"2022-04-27T02:15:37.5796Z","shell.execute_reply":"2022-04-27T02:15:40.753759Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_loader = torch.utils.data.DataLoader(\n    train_image,                                  \n    batch_size=32,\n    shuffle=True,\n    num_workers=2,\n)\n\nval_loader = torch.utils.data.DataLoader(\n    val_image,                                  \n    batch_size=2,\n    shuffle=True,\n    num_workers=2,\n)\n\ntest_loader = torch.utils.data.DataLoader(\n    test_image,                                  \n    batch_size=2,\n    shuffle=True,\n    num_workers=2,\n)","metadata":{"execution":{"iopub.status.busy":"2022-04-27T02:15:42.989215Z","iopub.execute_input":"2022-04-27T02:15:42.98997Z","iopub.status.idle":"2022-04-27T02:15:42.996289Z","shell.execute_reply.started":"2022-04-27T02:15:42.989929Z","shell.execute_reply":"2022-04-27T02:15:42.99562Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Defining some helper functions","metadata":{}},{"cell_type":"code","source":"class LRScheduler():\n    \"\"\"\n    Learning rate scheduler. If the validation loss does not decrease for the \n    given number of `patience` epochs, then the learning rate will decrease by\n    by given `factor`.\n    \"\"\"\n    def __init__(\n        self, optimizer, patience=5, min_lr=1e-6, factor=0.5\n    ):\n        \"\"\"\n        new_lr = old_lr * factor\n\n        :param optimizer: the optimizer we are using\n        :param patience: how many epochs to wait before updating the lr\n        :param min_lr: least lr value to reduce to while updating\n        :param factor: factor by which the lr should be updated\n        \"\"\"\n        self.optimizer = optimizer\n        self.patience = patience\n        self.min_lr = min_lr\n        self.factor = factor\n\n        self.lr_scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau( \n                self.optimizer,\n                mode='min',\n                patience=self.patience,\n                factor=self.factor,\n                min_lr=self.min_lr,\n                verbose=True\n            )\n\n    def __call__(self, val_loss):\n        self.lr_scheduler.step(val_loss)\n\nclass EarlyStopping():\n    \"\"\"\n    Early stopping to stop the training when the loss does not improve after\n    certain epochs.\n    \"\"\"\n    def __init__(self, patience=5, min_delta=0):\n        \"\"\"\n        :param patience: how many epochs to wait before stopping when loss is\n               not improving\n        :param min_delta: minimum difference between new loss and old loss for\n               new loss to be considered as an improvement\n        \"\"\"\n        self.patience = patience\n        self.min_delta = min_delta\n        self.counter = 0\n        self.best_loss = None\n        self.early_stop = False\n\n    def __call__(self, val_loss):\n        if self.best_loss == None:\n            self.best_loss = val_loss\n        elif self.best_loss - val_loss > self.min_delta:\n            self.best_loss = val_loss\n            # reset counter if validation loss improves\n            self.counter = 0\n        elif self.best_loss - val_loss < self.min_delta:\n            self.counter += 1\n            print(f\"INFO: Early stopping counter {self.counter} of {self.patience}\")\n            if self.counter >= self.patience:\n                print('INFO: Early stopping')\n                self.early_stop = True\n","metadata":{"execution":{"iopub.status.busy":"2022-04-27T02:15:45.84265Z","iopub.execute_input":"2022-04-27T02:15:45.842914Z","iopub.status.idle":"2022-04-27T02:15:45.85418Z","shell.execute_reply.started":"2022-04-27T02:15:45.842885Z","shell.execute_reply":"2022-04-27T02:15:45.853363Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def train(model, criterion, optimizer, device, train_loader, validation_loader, epochs, lr_scheduler_flag=False, early_stopping_flag=False):\n    train_loss, validation_loss = [], []\n    train_acc, validation_acc = [], []\n    for epoch in range(epochs):\n        model.train()\n        running_loss = 0.\n\n        correct, total = 0, 0 \n        with tqdm(train_loader, unit='batch') as tepoch:\n            tepoch.set_description('Training: ')\n            for data, target in tepoch:\n                data, target = data.to(device), target.to(device)\n                output = model(data)\n                optimizer.zero_grad()\n                loss = criterion(output, target)\n                loss.backward()\n                optimizer.step()\n                \n                tepoch.set_postfix(loss=loss.item())\n                running_loss += loss.item()\n                \n                _, predicted = torch.max(output, 1)\n                total += target.size(0)\n                correct += (predicted == target).sum().item()\n                \n        train_loss.append(running_loss / len(train_loader))  # append the loss for this epoch\n        train_acc.append(correct/total)\n                \n        # evaluate on validation data\n        \n        model.eval()\n        running_loss = 0.\n        correct, total = 0, 0 \n        with tqdm(validation_loader, unit='batch') as tepoch:\n            tepoch.set_description('Validation: ')\n            for data, target in tepoch:\n                data, target = data.to(device), target.to(device)\n                optimizer.zero_grad()\n                output = model(data)\n                \n                loss = criterion(output, target)\n                tepoch.set_postfix(loss=loss.item())\n                running_loss += loss.item()\n\n                # get accuracy \n                _, predicted = torch.max(output, 1)\n                total += target.size(0)\n                correct += (predicted == target).sum().item()\n        \n        validation_loss.append(running_loss/len(validation_loader))\n        validation_acc.append(correct/total)\n        \n        if validation_acc[-1] == 1: break\n        if lr_scheduler_flag:\n            lr_scheduler(validation_loss[-1])\n        if early_stopping_flag:\n            early_stopping(validation_loss[-1])\n            if early_stopping.early_stop:\n                break\n    \n    return train_loss, train_acc, validation_loss, validation_acc ","metadata":{"execution":{"iopub.status.busy":"2022-04-27T02:15:49.577804Z","iopub.execute_input":"2022-04-27T02:15:49.578182Z","iopub.status.idle":"2022-04-27T02:15:49.591648Z","shell.execute_reply.started":"2022-04-27T02:15:49.578147Z","shell.execute_reply":"2022-04-27T02:15:49.590948Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def plot_loss_accuracy(train_loss, train_acc, validation_loss, validation_acc):\n    epochs = len(train_loss)\n    fig, (ax1, ax2) = plt.subplots(1, 2)\n    ax1.plot(list(range(epochs)), train_loss, label='Training Loss')\n    ax1.plot(list(range(epochs)), validation_loss, label='Validation Loss')\n    ax1.set_xlabel('Epochs')\n    ax1.set_ylabel('Loss')\n    ax1.set_title('Epoch vs Loss')\n    ax1.legend()\n\n    ax2.plot(list(range(epochs)), train_acc, label='Training Accuracy')\n    ax2.plot(list(range(epochs)), validation_acc, label='Validation Accuracy')\n    ax2.set_xlabel('Epochs')\n    ax2.set_ylabel('Accuracy')\n    ax2.set_title('Epoch vs Accuracy')\n    ax2.legend()\n    fig.set_size_inches(15.5, 5.5)\n    plt.show()","metadata":{"execution":{"iopub.status.busy":"2022-04-27T02:15:52.872739Z","iopub.execute_input":"2022-04-27T02:15:52.873295Z","iopub.status.idle":"2022-04-27T02:15:52.879944Z","shell.execute_reply.started":"2022-04-27T02:15:52.87326Z","shell.execute_reply":"2022-04-27T02:15:52.879232Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# VGG19","metadata":{}},{"cell_type":"code","source":"vgg_model = models.vgg19(pretrained=True)\nfor param in vgg_model.parameters():\n  param.requires_grad = False\n\nfor param in vgg_model.classifier.parameters():\n    param.requires_grad = True\n\nnum_ftrs = vgg_model.classifier[-1].in_features\n\nvgg_model.classifier[-1] = nn.Sequential(\n    nn.Linear(num_ftrs, 2)\n)\nvgg_model = vgg_model.to(DEVICE)\nprint(vgg_model)","metadata":{"execution":{"iopub.status.busy":"2022-04-18T01:09:48.0332Z","iopub.execute_input":"2022-04-18T01:09:48.033847Z","iopub.status.idle":"2022-04-18T01:10:05.805744Z","shell.execute_reply.started":"2022-04-18T01:09:48.033813Z","shell.execute_reply":"2022-04-18T01:10:05.805011Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"optimizer = torch.optim.Adam(vgg_model.parameters(), lr=1e-5)\nlr_scheduler = LRScheduler(optimizer)\nearly_stopping = EarlyStopping(patience=3)\nloss_fn = nn.CrossEntropyLoss()","metadata":{"execution":{"iopub.status.busy":"2022-04-18T01:10:05.808393Z","iopub.execute_input":"2022-04-18T01:10:05.808791Z","iopub.status.idle":"2022-04-18T01:10:05.816097Z","shell.execute_reply.started":"2022-04-18T01:10:05.808745Z","shell.execute_reply":"2022-04-18T01:10:05.813476Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_loss, train_acc, validation_loss, validation_acc = train(\n    vgg_model, loss_fn, optimizer, DEVICE, train_loader, val_loader, 20,\n    lr_scheduler_flag=True, early_stopping_flag=False\n)\nplot_loss_accuracy(train_loss, train_acc, validation_loss, validation_acc)","metadata":{"execution":{"iopub.status.busy":"2022-04-18T01:10:05.817404Z","iopub.execute_input":"2022-04-18T01:10:05.817868Z","iopub.status.idle":"2022-04-18T01:33:17.93774Z","shell.execute_reply.started":"2022-04-18T01:10:05.817832Z","shell.execute_reply":"2022-04-18T01:33:17.937014Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print(\n    \"train_loss:\", train_loss, \n    \"\\ntrain_acc:\", train_acc, \n    \"\\nvalidation_loss:\", validation_loss, \n    \"validation_acc:\", validation_acc\n)","metadata":{"execution":{"iopub.status.busy":"2022-04-18T01:33:17.939152Z","iopub.execute_input":"2022-04-18T01:33:17.939964Z","iopub.status.idle":"2022-04-18T01:33:17.946762Z","shell.execute_reply.started":"2022-04-18T01:33:17.939897Z","shell.execute_reply":"2022-04-18T01:33:17.94597Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Evaluating VGG19","metadata":{}},{"cell_type":"code","source":"with torch.no_grad():\n    loss_sum = 0\n    total_correct = 0\n    total = len(test_image)\n    for batch in test_loader:\n      images, labels = batch\n      images = images.to(DEVICE)\n      labels = labels.to(DEVICE)\n      output = vgg_model(images)\n      loss = loss_fn(output, labels)\n      loss_sum += loss.item()\n\n      predictions = torch.argmax(output, dim=1)\n\n      num_correct = torch.sum(predictions == labels)\n      total_correct += num_correct.cpu()\n\npct = total_correct / total\nprint(f'\\n Final accuracy is {pct}')","metadata":{"execution":{"iopub.status.busy":"2022-04-18T01:33:17.948135Z","iopub.execute_input":"2022-04-18T01:33:17.948457Z","iopub.status.idle":"2022-04-18T01:33:30.033216Z","shell.execute_reply.started":"2022-04-18T01:33:17.948422Z","shell.execute_reply":"2022-04-18T01:33:30.032267Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def get_y(net, test_loader, device):\n    y_pred=torch.zeros(0,dtype=torch.long, device='cpu')\n    y_true=torch.zeros(0,dtype=torch.long, device='cpu')\n    with torch.no_grad():\n      for batch in test_loader:\n        data, label = batch\n        data, label = data.to(device), label.to(device)\n        outputs = net(data)\n        _, preds = torch.max(outputs, 1)\n        y_pred = torch.cat([y_pred, preds.view(-1).cpu()])\n        y_true = torch.cat([y_true, label.view(-1).cpu()])\n\n    return y_pred, y_true","metadata":{"execution":{"iopub.status.busy":"2022-04-18T03:03:28.074112Z","iopub.execute_input":"2022-04-18T03:03:28.074432Z","iopub.status.idle":"2022-04-18T03:03:28.082511Z","shell.execute_reply.started":"2022-04-18T03:03:28.0744Z","shell.execute_reply":"2022-04-18T03:03:28.081533Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"y_pred, y_true = get_y(vgg_model, test_loader, DEVICE)\nconfusion_matrix_df = pd.DataFrame(confusion_matrix(y_true, y_pred))","metadata":{"execution":{"iopub.status.busy":"2022-04-18T01:59:03.279113Z","iopub.execute_input":"2022-04-18T01:59:03.279775Z","iopub.status.idle":"2022-04-18T01:59:14.030453Z","shell.execute_reply.started":"2022-04-18T01:59:03.279734Z","shell.execute_reply":"2022-04-18T01:59:14.029553Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"plt.figure(figsize=(16,8))\nsns.heatmap(confusion_matrix_df, cmap=\"RdBu\", annot=True)\nplt.title('Confusion Matrix Heatmap', fontsize=16)\nplt.xlabel(\"Predicted condition\")\nplt.ylabel(\"Actual condition\")\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2022-04-18T01:59:25.26147Z","iopub.execute_input":"2022-04-18T01:59:25.261746Z","iopub.status.idle":"2022-04-18T01:59:25.520034Z","shell.execute_reply.started":"2022-04-18T01:59:25.261711Z","shell.execute_reply":"2022-04-18T01:59:25.519329Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"precision_recall_fscore_support(y_true, y_pred, average=\"binary\")","metadata":{"execution":{"iopub.status.busy":"2022-04-18T02:00:01.50574Z","iopub.execute_input":"2022-04-18T02:00:01.506053Z","iopub.status.idle":"2022-04-18T02:00:01.516803Z","shell.execute_reply.started":"2022-04-18T02:00:01.506018Z","shell.execute_reply":"2022-04-18T02:00:01.51589Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Basic CNN","metadata":{}},{"cell_type":"code","source":"class CNN(nn.Module):\n  def __init__(self):\n    super(CNN, self).__init__()\n    self.conv1 = nn.Conv2d(in_channels=3, out_channels=16, kernel_size=3)\n    self.conv2 = nn.Conv2d(in_channels=16, out_channels=32, kernel_size=3)\n    self.fc1 = nn.Linear(in_features=387200, out_features=128)\n    self.fc2 = nn.Linear(in_features=128, out_features=2)\n    self.pool = nn.MaxPool2d(kernel_size=2, stride=2)\n    self.relu = nn.ReLU()\n\n  def forward(self, x):\n    x = self.conv1(x)\n    x = self.relu(x)\n    x = self.conv2(x)\n    x = self.relu(x)\n    x = self.pool(x)\n    x = x.flatten(start_dim=1)\n    x = self.fc1(x)\n    x = self.relu(x)\n    x = self.fc2(x)\n    return x","metadata":{"execution":{"iopub.status.busy":"2022-04-27T02:15:55.678477Z","iopub.execute_input":"2022-04-27T02:15:55.678766Z","iopub.status.idle":"2022-04-27T02:15:55.687474Z","shell.execute_reply.started":"2022-04-27T02:15:55.678736Z","shell.execute_reply":"2022-04-27T02:15:55.68671Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"cnn_net = CNN().to(DEVICE)\ncnn_optimizer = torch.optim.Adam(cnn_net.parameters(), lr=1e-5)\nloss_fn = nn.CrossEntropyLoss()","metadata":{"execution":{"iopub.status.busy":"2022-04-27T02:15:58.062044Z","iopub.execute_input":"2022-04-27T02:15:58.062731Z","iopub.status.idle":"2022-04-27T02:16:01.426308Z","shell.execute_reply.started":"2022-04-27T02:15:58.062691Z","shell.execute_reply":"2022-04-27T02:16:01.425584Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import torch.onnx\ntorch.onnx.export(cnn_net,               # model being run\n                  torch.rand(16, 3, 224, 224).to(DEVICE),                         # model input (or a tuple for multiple inputs)\n                  \"cnn.onnx\",   # where to save the model (can be a file or file-like object)\n                  export_params=True,        # store the trained parameter weights inside the model file\n                  opset_version=10,          # the ONNX version to export the model to\n                  do_constant_folding=True,  # whether to execute constant folding for optimization\n                  input_names = ['input'],   # the model's input names\n                  output_names = ['output'], # the model's output names\n                  dynamic_axes={'input' : {0 : 'batch_size'},    # variable length axes\n                                'output' : {0 : 'batch_size'}})","metadata":{"execution":{"iopub.status.busy":"2022-04-27T02:29:27.528492Z","iopub.execute_input":"2022-04-27T02:29:27.529204Z","iopub.status.idle":"2022-04-27T02:29:30.651961Z","shell.execute_reply.started":"2022-04-27T02:29:27.529165Z","shell.execute_reply":"2022-04-27T02:29:30.651184Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_loss, train_acc, validation_loss, validation_acc = train(\n    cnn_net, loss_fn, cnn_optimizer, DEVICE, train_loader, val_loader, 20\n)\nplot_loss_accuracy(train_loss, train_acc, validation_loss, validation_acc)","metadata":{"execution":{"iopub.status.busy":"2022-04-18T02:31:03.523199Z","iopub.execute_input":"2022-04-18T02:31:03.523474Z","iopub.status.idle":"2022-04-18T03:00:43.442606Z","shell.execute_reply.started":"2022-04-18T02:31:03.523445Z","shell.execute_reply":"2022-04-18T03:00:43.439884Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Evaluating CNN","metadata":{}},{"cell_type":"code","source":"with torch.no_grad():\n    loss_sum = 0\n    total_correct = 0\n    total = len(test_image)\n    for batch in test_loader:\n      images, labels = batch\n      images = images.to(DEVICE)\n      labels = labels.to(DEVICE)\n      output = cnn_net(images)\n      loss = loss_fn(output, labels)\n      loss_sum += loss.item()\n\n      predictions = torch.argmax(output, dim=1)\n\n      num_correct = torch.sum(predictions == labels)\n      total_correct += num_correct.cpu()\n\npct = total_correct / total\nprint(f'\\n Final accuracy is {pct}')","metadata":{"execution":{"iopub.status.busy":"2022-04-18T03:03:03.70856Z","iopub.execute_input":"2022-04-18T03:03:03.709173Z","iopub.status.idle":"2022-04-18T03:03:15.786279Z","shell.execute_reply.started":"2022-04-18T03:03:03.709093Z","shell.execute_reply":"2022-04-18T03:03:15.785297Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"y_pred, y_true = get_y(cnn_net, test_loader, DEVICE)\nconfusion_matrix_df = pd.DataFrame(confusion_matrix(y_true, y_pred))","metadata":{"execution":{"iopub.status.busy":"2022-04-18T03:03:32.633043Z","iopub.execute_input":"2022-04-18T03:03:32.633532Z","iopub.status.idle":"2022-04-18T03:03:43.779034Z","shell.execute_reply.started":"2022-04-18T03:03:32.633494Z","shell.execute_reply":"2022-04-18T03:03:43.778046Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"plt.figure(figsize=(16,8))\nsns.heatmap(confusion_matrix_df, cmap=\"RdBu\", annot=True)\nplt.title('Confusion Matrix Heatmap', fontsize=16)\nplt.xlabel(\"Predicted condition\")\nplt.ylabel(\"Actual condition\")\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2022-04-18T03:03:54.013644Z","iopub.execute_input":"2022-04-18T03:03:54.01395Z","iopub.status.idle":"2022-04-18T03:03:54.259471Z","shell.execute_reply.started":"2022-04-18T03:03:54.013906Z","shell.execute_reply":"2022-04-18T03:03:54.258777Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"precision_recall_fscore_support(y_true, y_pred, average=\"binary\")","metadata":{"execution":{"iopub.status.busy":"2022-04-18T03:03:58.51404Z","iopub.execute_input":"2022-04-18T03:03:58.514759Z","iopub.status.idle":"2022-04-18T03:03:58.526232Z","shell.execute_reply.started":"2022-04-18T03:03:58.51472Z","shell.execute_reply":"2022-04-18T03:03:58.525369Z"},"trusted":true},"execution_count":null,"outputs":[]}]}